事故率と「人だったら回避できたのに、システムだから回避できなかった事故」将来技術がどんどん洗練されていくと、統計的に、事故率において、システムによる事故率が人による事故率を大幅に下まわるようになっていくことが期待されます。しかし、システムの事故率が人の事故率を大幅に下まわるようなときがきても、それでも「人だったら簡単に回避できたのに、システムだから回避できなかった事故」が一定数は残るということが想定されます。このような問題は、人工知能が意味を理解するという質的な技術発展が起きるまで残ると思われます。このように、「システムによる事故率が人による事故率を大幅に下まわっている」にもかかわらず、「人だったら簡単に回避できたのにシステムだったから回避できなかった事故」が起きたとき、その自動走行システムはあるべき安全性を備えていなかったと評価するべきなのか、メーカー関係者の責任が問われるべきなのかという問題に直面することになります。技術の限界やリスクとも正面から向き合うこのような非常に難しい本質的な問題を踏まえて、「認知・予測・判断・操作」に関する技術基準をどのように具体化していくのかということが、現在自動運転に関する法制度が直面している大きな課題のひとつです。新しい技術の社会実装のための法制度を作っていくに当たっては、技術をきちんと理解し、メリットだけではなく、技術の限界やリスクにも正面から向き合い、議論を尽くすということが大切だと考えます。そうすることが、納得感をもった健全な社会実装につながっていくと考えています。